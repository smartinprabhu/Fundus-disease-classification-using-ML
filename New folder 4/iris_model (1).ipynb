{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d0a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d1db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23d4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = pathlib.Path(\"C:/Users/testi/OneDrive/Documents/Python Scripts/Demo Dataset - Iris Defect Detection Project Demo - Menmozhi Technologies/dataset/normal\") # Path to normal images directory\n",
    "glaucoma = pathlib.Path(\"C:/Users/testi/OneDrive/Documents/Python Scripts/Demo Dataset - Iris Defect Detection Project Demo - Menmozhi Technologies/dataset/glaucoma\") # Path to glaucoma images directory\n",
    "retinopathy = pathlib.Path(\"C:/Users/testi/OneDrive/Documents/Python Scripts/Demo Dataset - Iris Defect Detection Project Demo - Menmozhi Technologies/dataset/diabetic_retinopathy\") # Path to diabetic retinopathy images directory\n",
    "cataract = pathlib.Path(\"C:/Users/testi/OneDrive/Documents/Python Scripts/Demo Dataset - Iris Defect Detection Project Demo - Menmozhi Technologies/dataset/cataract\") # Path to cataract images directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44123bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of image paths\n",
    "images_dict = {\n",
    "    \"normal\": list(normal.glob(\"*.jpg\")),\n",
    "    \"glaucoma\": list(glaucoma.glob(\"*.jpg\")),\n",
    "    \"diabetic_retinopathy\": list(retinopathy.glob(\"*.jpg\")),\n",
    "    \"cataract\": list(cataract.glob(\"*.jpg\"))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3121b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define labels dictionary\n",
    "labels_dict = {\n",
    "    \"normal\": 0, \"glaucoma\": 1, \"diabetic_retinopathy\": 2, \"cataract\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51f01860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "X, y = [], []\n",
    "for label, images in images_dict.items():\n",
    "    for image in images:\n",
    "        image = cv2.imread(str(image))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (180, 180))\n",
    "        if image is not None:\n",
    "            X.append(image)\n",
    "            y.append(labels_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d70152a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X) / 255.0\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e275d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0723ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    keras.layers.experimental.preprocessing.RandomContrast(0.3),\n",
    "    keras.layers.experimental.preprocessing.RandomZoom(0.3),\n",
    "    keras.layers.experimental.preprocessing.RandomZoom(0.7)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "732a9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(64, (5, 5), padding=\"same\", input_shape=(180, 180, 3), activation=\"softmax\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, (5, 5), padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(16, (5, 5), padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(8, (5, 5), padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(50, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ec90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d10cc60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "64/64 [==============================] - 75s 929ms/step - loss: 1.4582 - accuracy: 0.3173\n",
      "Epoch 2/500\n",
      "64/64 [==============================] - 61s 957ms/step - loss: 1.1182 - accuracy: 0.3531\n",
      "Epoch 3/500\n",
      "64/64 [==============================] - 57s 895ms/step - loss: 1.1176 - accuracy: 0.3448\n",
      "Epoch 4/500\n",
      "64/64 [==============================] - 55s 867ms/step - loss: 1.0771 - accuracy: 0.3967\n",
      "Epoch 5/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 1.0839 - accuracy: 0.3942\n",
      "Epoch 6/500\n",
      "64/64 [==============================] - 56s 879ms/step - loss: 1.0791 - accuracy: 0.3908\n",
      "Epoch 7/500\n",
      "64/64 [==============================] - 56s 873ms/step - loss: 1.0592 - accuracy: 0.4148\n",
      "Epoch 8/500\n",
      "64/64 [==============================] - 57s 894ms/step - loss: 1.0544 - accuracy: 0.4172\n",
      "Epoch 9/500\n",
      "64/64 [==============================] - 64s 996ms/step - loss: 1.0555 - accuracy: 0.4295\n",
      "Epoch 10/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 1.0458 - accuracy: 0.4452\n",
      "Epoch 11/500\n",
      "64/64 [==============================] - 57s 883ms/step - loss: 1.0298 - accuracy: 0.4476\n",
      "Epoch 12/500\n",
      "64/64 [==============================] - 59s 919ms/step - loss: 1.0390 - accuracy: 0.4554\n",
      "Epoch 13/500\n",
      "64/64 [==============================] - 60s 933ms/step - loss: 1.0141 - accuracy: 0.4755\n",
      "Epoch 14/500\n",
      "64/64 [==============================] - 59s 922ms/step - loss: 1.0051 - accuracy: 0.4829\n",
      "Epoch 15/500\n",
      "64/64 [==============================] - 61s 949ms/step - loss: 0.9917 - accuracy: 0.4882\n",
      "Epoch 16/500\n",
      "64/64 [==============================] - 59s 920ms/step - loss: 0.9810 - accuracy: 0.4956\n",
      "Epoch 17/500\n",
      "64/64 [==============================] - 56s 883ms/step - loss: 0.9540 - accuracy: 0.5137\n",
      "Epoch 18/500\n",
      "64/64 [==============================] - 57s 894ms/step - loss: 0.9475 - accuracy: 0.5294\n",
      "Epoch 19/500\n",
      "64/64 [==============================] - 57s 896ms/step - loss: 0.9484 - accuracy: 0.5215\n",
      "Epoch 20/500\n",
      "64/64 [==============================] - 54s 847ms/step - loss: 0.9290 - accuracy: 0.5304\n",
      "Epoch 21/500\n",
      "64/64 [==============================] - 54s 851ms/step - loss: 0.9279 - accuracy: 0.5279\n",
      "Epoch 22/500\n",
      "64/64 [==============================] - 54s 840ms/step - loss: 0.9216 - accuracy: 0.5372\n",
      "Epoch 23/500\n",
      "64/64 [==============================] - 58s 903ms/step - loss: 0.9106 - accuracy: 0.5475\n",
      "Epoch 24/500\n",
      "64/64 [==============================] - 57s 884ms/step - loss: 0.9266 - accuracy: 0.5411\n",
      "Epoch 25/500\n",
      "64/64 [==============================] - 56s 875ms/step - loss: 0.9078 - accuracy: 0.5460\n",
      "Epoch 26/500\n",
      "64/64 [==============================] - 56s 871ms/step - loss: 0.9119 - accuracy: 0.5382\n",
      "Epoch 27/500\n",
      "64/64 [==============================] - 57s 885ms/step - loss: 0.8964 - accuracy: 0.5607\n",
      "Epoch 28/500\n",
      "64/64 [==============================] - 61s 945ms/step - loss: 0.9123 - accuracy: 0.5568\n",
      "Epoch 29/500\n",
      "64/64 [==============================] - 63s 985ms/step - loss: 0.8893 - accuracy: 0.5695\n",
      "Epoch 30/500\n",
      "64/64 [==============================] - 74s 1s/step - loss: 0.8851 - accuracy: 0.5769\n",
      "Epoch 31/500\n",
      "64/64 [==============================] - 61s 951ms/step - loss: 0.8766 - accuracy: 0.5686\n",
      "Epoch 32/500\n",
      "64/64 [==============================] - 63s 982ms/step - loss: 0.8819 - accuracy: 0.5774\n",
      "Epoch 33/500\n",
      "64/64 [==============================] - 58s 899ms/step - loss: 0.8847 - accuracy: 0.5833\n",
      "Epoch 34/500\n",
      "64/64 [==============================] - 60s 931ms/step - loss: 0.8704 - accuracy: 0.5945\n",
      "Epoch 35/500\n",
      "64/64 [==============================] - 61s 953ms/step - loss: 0.8487 - accuracy: 0.5852\n",
      "Epoch 36/500\n",
      "64/64 [==============================] - 59s 924ms/step - loss: 0.8530 - accuracy: 0.5979\n",
      "Epoch 37/500\n",
      "64/64 [==============================] - 60s 940ms/step - loss: 0.8519 - accuracy: 0.5911\n",
      "Epoch 38/500\n",
      "64/64 [==============================] - 61s 946ms/step - loss: 0.8591 - accuracy: 0.5798\n",
      "Epoch 39/500\n",
      "64/64 [==============================] - 61s 950ms/step - loss: 0.8576 - accuracy: 0.5877\n",
      "Epoch 40/500\n",
      "64/64 [==============================] - 58s 914ms/step - loss: 0.8443 - accuracy: 0.6009\n",
      "Epoch 41/500\n",
      "64/64 [==============================] - 60s 945ms/step - loss: 0.8398 - accuracy: 0.6048\n",
      "Epoch 42/500\n",
      "64/64 [==============================] - 59s 921ms/step - loss: 0.8406 - accuracy: 0.6112\n",
      "Epoch 43/500\n",
      "64/64 [==============================] - 63s 986ms/step - loss: 0.8433 - accuracy: 0.6028\n",
      "Epoch 44/500\n",
      "64/64 [==============================] - 61s 955ms/step - loss: 0.8589 - accuracy: 0.5911\n",
      "Epoch 45/500\n",
      "64/64 [==============================] - 61s 949ms/step - loss: 0.8413 - accuracy: 0.5896\n",
      "Epoch 46/500\n",
      "64/64 [==============================] - 59s 915ms/step - loss: 0.8473 - accuracy: 0.5975\n",
      "Epoch 47/500\n",
      "64/64 [==============================] - 61s 946ms/step - loss: 0.8383 - accuracy: 0.6038\n",
      "Epoch 48/500\n",
      "64/64 [==============================] - 62s 972ms/step - loss: 0.8300 - accuracy: 0.5994\n",
      "Epoch 49/500\n",
      "64/64 [==============================] - 62s 964ms/step - loss: 0.8146 - accuracy: 0.6244\n",
      "Epoch 50/500\n",
      "64/64 [==============================] - 62s 977ms/step - loss: 0.8394 - accuracy: 0.6048\n",
      "Epoch 51/500\n",
      "64/64 [==============================] - 61s 956ms/step - loss: 0.8255 - accuracy: 0.6014\n",
      "Epoch 52/500\n",
      "64/64 [==============================] - 63s 978ms/step - loss: 0.8383 - accuracy: 0.5877\n",
      "Epoch 53/500\n",
      "64/64 [==============================] - 60s 941ms/step - loss: 0.8053 - accuracy: 0.6190\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 64s 1s/step - loss: 0.8399 - accuracy: 0.5940\n",
      "Epoch 55/500\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.8022 - accuracy: 0.6312\n",
      "Epoch 56/500\n",
      "64/64 [==============================] - 61s 959ms/step - loss: 0.8019 - accuracy: 0.6332\n",
      "Epoch 57/500\n",
      "64/64 [==============================] - 60s 933ms/step - loss: 0.8016 - accuracy: 0.6278\n",
      "Epoch 58/500\n",
      "64/64 [==============================] - 62s 966ms/step - loss: 0.8081 - accuracy: 0.6185\n",
      "Epoch 59/500\n",
      "64/64 [==============================] - 63s 986ms/step - loss: 0.8167 - accuracy: 0.6259\n",
      "Epoch 60/500\n",
      "64/64 [==============================] - 60s 923ms/step - loss: 0.7799 - accuracy: 0.6376\n",
      "Epoch 61/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.7936 - accuracy: 0.6283\n",
      "Epoch 62/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.8024 - accuracy: 0.6219\n",
      "Epoch 63/500\n",
      "64/64 [==============================] - 58s 913ms/step - loss: 0.8019 - accuracy: 0.6342\n",
      "Epoch 64/500\n",
      "64/64 [==============================] - 57s 895ms/step - loss: 0.7982 - accuracy: 0.6239\n",
      "Epoch 65/500\n",
      "64/64 [==============================] - 57s 894ms/step - loss: 0.8137 - accuracy: 0.6229\n",
      "Epoch 66/500\n",
      "64/64 [==============================] - 59s 916ms/step - loss: 0.8055 - accuracy: 0.6263\n",
      "Epoch 67/500\n",
      "64/64 [==============================] - 59s 917ms/step - loss: 0.7940 - accuracy: 0.6391\n",
      "Epoch 68/500\n",
      "64/64 [==============================] - 59s 919ms/step - loss: 0.7876 - accuracy: 0.6303\n",
      "Epoch 69/500\n",
      "64/64 [==============================] - 63s 991ms/step - loss: 0.7753 - accuracy: 0.6508\n",
      "Epoch 70/500\n",
      "64/64 [==============================] - 62s 963ms/step - loss: 0.7862 - accuracy: 0.6234\n",
      "Epoch 71/500\n",
      "64/64 [==============================] - 61s 949ms/step - loss: 0.7769 - accuracy: 0.6259\n",
      "Epoch 72/500\n",
      "64/64 [==============================] - 60s 945ms/step - loss: 0.7745 - accuracy: 0.6308\n",
      "Epoch 73/500\n",
      "64/64 [==============================] - 62s 970ms/step - loss: 0.7815 - accuracy: 0.6278\n",
      "Epoch 74/500\n",
      "64/64 [==============================] - 61s 951ms/step - loss: 0.7688 - accuracy: 0.6401\n",
      "Epoch 75/500\n",
      "64/64 [==============================] - 61s 954ms/step - loss: 0.8039 - accuracy: 0.6283\n",
      "Epoch 76/500\n",
      "64/64 [==============================] - 63s 991ms/step - loss: 0.7800 - accuracy: 0.6440\n",
      "Epoch 77/500\n",
      "64/64 [==============================] - 62s 976ms/step - loss: 0.7857 - accuracy: 0.6396\n",
      "Epoch 78/500\n",
      "64/64 [==============================] - 61s 947ms/step - loss: 0.7749 - accuracy: 0.6386\n",
      "Epoch 79/500\n",
      "64/64 [==============================] - 60s 935ms/step - loss: 0.7816 - accuracy: 0.6440\n",
      "Epoch 80/500\n",
      "64/64 [==============================] - 59s 923ms/step - loss: 0.7675 - accuracy: 0.6435\n",
      "Epoch 81/500\n",
      "64/64 [==============================] - 60s 935ms/step - loss: 0.7666 - accuracy: 0.6489\n",
      "Epoch 82/500\n",
      "64/64 [==============================] - 61s 949ms/step - loss: 0.7755 - accuracy: 0.6401\n",
      "Epoch 83/500\n",
      "64/64 [==============================] - 59s 921ms/step - loss: 0.7637 - accuracy: 0.6450\n",
      "Epoch 84/500\n",
      "64/64 [==============================] - 61s 948ms/step - loss: 0.7647 - accuracy: 0.6499\n",
      "Epoch 85/500\n",
      "64/64 [==============================] - 60s 938ms/step - loss: 0.7549 - accuracy: 0.6601\n",
      "Epoch 86/500\n",
      "64/64 [==============================] - 59s 921ms/step - loss: 0.7423 - accuracy: 0.6616\n",
      "Epoch 87/500\n",
      "64/64 [==============================] - 59s 923ms/step - loss: 0.7608 - accuracy: 0.6469\n",
      "Epoch 88/500\n",
      "64/64 [==============================] - 61s 954ms/step - loss: 0.7797 - accuracy: 0.6361\n",
      "Epoch 89/500\n",
      "64/64 [==============================] - 60s 934ms/step - loss: 0.7531 - accuracy: 0.6587\n",
      "Epoch 90/500\n",
      "64/64 [==============================] - 61s 959ms/step - loss: 0.7656 - accuracy: 0.6626\n",
      "Epoch 91/500\n",
      "64/64 [==============================] - 60s 938ms/step - loss: 0.7607 - accuracy: 0.6528\n",
      "Epoch 92/500\n",
      "64/64 [==============================] - 61s 961ms/step - loss: 0.7527 - accuracy: 0.6753\n",
      "Epoch 93/500\n",
      "64/64 [==============================] - 60s 937ms/step - loss: 0.7624 - accuracy: 0.6577\n",
      "Epoch 94/500\n",
      "64/64 [==============================] - 60s 940ms/step - loss: 0.7599 - accuracy: 0.6626\n",
      "Epoch 95/500\n",
      "64/64 [==============================] - 58s 912ms/step - loss: 0.7708 - accuracy: 0.6484\n",
      "Epoch 96/500\n",
      "64/64 [==============================] - 59s 928ms/step - loss: 0.7457 - accuracy: 0.6719\n",
      "Epoch 97/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.7373 - accuracy: 0.6704\n",
      "Epoch 98/500\n",
      "64/64 [==============================] - 60s 945ms/step - loss: 0.7423 - accuracy: 0.6645\n",
      "Epoch 99/500\n",
      "64/64 [==============================] - 59s 918ms/step - loss: 0.7507 - accuracy: 0.6748\n",
      "Epoch 100/500\n",
      "64/64 [==============================] - 60s 938ms/step - loss: 0.7478 - accuracy: 0.6528\n",
      "Epoch 101/500\n",
      "64/64 [==============================] - 60s 934ms/step - loss: 0.7391 - accuracy: 0.6783\n",
      "Epoch 102/500\n",
      "64/64 [==============================] - 57s 898ms/step - loss: 0.7302 - accuracy: 0.6606\n",
      "Epoch 103/500\n",
      "64/64 [==============================] - 59s 920ms/step - loss: 0.7408 - accuracy: 0.6797\n",
      "Epoch 104/500\n",
      "64/64 [==============================] - 73s 1s/step - loss: 0.7355 - accuracy: 0.6675\n",
      "Epoch 105/500\n",
      "64/64 [==============================] - 61s 946ms/step - loss: 0.7481 - accuracy: 0.6670\n",
      "Epoch 106/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.7509 - accuracy: 0.6606\n",
      "Epoch 107/500\n",
      "64/64 [==============================] - 61s 951ms/step - loss: 0.7321 - accuracy: 0.6802\n",
      "Epoch 108/500\n",
      "64/64 [==============================] - 68s 1s/step - loss: 0.7273 - accuracy: 0.6665\n",
      "Epoch 109/500\n",
      "64/64 [==============================] - 60s 936ms/step - loss: 0.7306 - accuracy: 0.6763\n",
      "Epoch 110/500\n",
      "64/64 [==============================] - 62s 968ms/step - loss: 0.7263 - accuracy: 0.6768\n",
      "Epoch 111/500\n",
      "64/64 [==============================] - 62s 969ms/step - loss: 0.7165 - accuracy: 0.6758\n",
      "Epoch 112/500\n",
      "64/64 [==============================] - 63s 983ms/step - loss: 0.7329 - accuracy: 0.6694\n",
      "Epoch 113/500\n",
      "64/64 [==============================] - 59s 929ms/step - loss: 0.7276 - accuracy: 0.6773\n",
      "Epoch 114/500\n",
      "64/64 [==============================] - 67s 1s/step - loss: 0.7445 - accuracy: 0.6680\n",
      "Epoch 115/500\n",
      "64/64 [==============================] - 59s 926ms/step - loss: 0.7423 - accuracy: 0.6670\n",
      "Epoch 116/500\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.7127 - accuracy: 0.6802\n",
      "Epoch 117/500\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.7287 - accuracy: 0.6822\n",
      "Epoch 118/500\n",
      "64/64 [==============================] - 62s 975ms/step - loss: 0.7193 - accuracy: 0.6724\n",
      "Epoch 119/500\n",
      "64/64 [==============================] - 60s 941ms/step - loss: 0.7370 - accuracy: 0.6626\n",
      "Epoch 120/500\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.7409 - accuracy: 0.6611\n",
      "Epoch 121/500\n",
      "64/64 [==============================] - 62s 972ms/step - loss: 0.7243 - accuracy: 0.6773\n",
      "Epoch 122/500\n",
      "64/64 [==============================] - 62s 977ms/step - loss: 0.7161 - accuracy: 0.6802\n",
      "Epoch 123/500\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.7255 - accuracy: 0.6802\n",
      "Epoch 124/500\n",
      "64/64 [==============================] - 62s 967ms/step - loss: 0.7088 - accuracy: 0.6827\n",
      "Epoch 125/500\n",
      "64/64 [==============================] - 66s 997ms/step - loss: 0.7347 - accuracy: 0.6611\n",
      "Epoch 126/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.7244 - accuracy: 0.6724\n",
      "Epoch 127/500\n",
      "64/64 [==============================] - 69s 1s/step - loss: 0.7095 - accuracy: 0.6861\n",
      "Epoch 128/500\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.7102 - accuracy: 0.6851\n",
      "Epoch 129/500\n",
      "64/64 [==============================] - 58s 912ms/step - loss: 0.7276 - accuracy: 0.6783\n",
      "Epoch 130/500\n",
      "64/64 [==============================] - 63s 989ms/step - loss: 0.7131 - accuracy: 0.6792\n",
      "Epoch 131/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.7172 - accuracy: 0.6861\n",
      "Epoch 132/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.7067 - accuracy: 0.6895\n",
      "Epoch 133/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 65s 1s/step - loss: 0.7269 - accuracy: 0.6787\n",
      "Epoch 134/500\n",
      "64/64 [==============================] - 60s 938ms/step - loss: 0.7123 - accuracy: 0.6832\n",
      "Epoch 135/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.7265 - accuracy: 0.6856\n",
      "Epoch 136/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.7163 - accuracy: 0.6856\n",
      "Epoch 137/500\n",
      "64/64 [==============================] - 64s 1s/step - loss: 0.7056 - accuracy: 0.6881\n",
      "Epoch 138/500\n",
      "64/64 [==============================] - 63s 987ms/step - loss: 0.7122 - accuracy: 0.6836\n",
      "Epoch 139/500\n",
      "64/64 [==============================] - 60s 944ms/step - loss: 0.7092 - accuracy: 0.6905\n",
      "Epoch 140/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.6933 - accuracy: 0.6925\n",
      "Epoch 141/500\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.7063 - accuracy: 0.6866\n",
      "Epoch 142/500\n",
      "64/64 [==============================] - 62s 972ms/step - loss: 0.7191 - accuracy: 0.6822\n",
      "Epoch 143/500\n",
      "64/64 [==============================] - 69s 1s/step - loss: 0.6972 - accuracy: 0.6954\n",
      "Epoch 144/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.6922 - accuracy: 0.6910\n",
      "Epoch 145/500\n",
      "64/64 [==============================] - 69s 1s/step - loss: 0.7158 - accuracy: 0.6797\n",
      "Epoch 146/500\n",
      "64/64 [==============================] - 63s 991ms/step - loss: 0.7151 - accuracy: 0.6797\n",
      "Epoch 147/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.6725 - accuracy: 0.6993\n",
      "Epoch 148/500\n",
      "64/64 [==============================] - 62s 975ms/step - loss: 0.7081 - accuracy: 0.6773\n",
      "Epoch 149/500\n",
      "64/64 [==============================] - 67s 1s/step - loss: 0.6925 - accuracy: 0.6993\n",
      "Epoch 150/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.7154 - accuracy: 0.6699\n",
      "Epoch 151/500\n",
      "64/64 [==============================] - 62s 974ms/step - loss: 0.6949 - accuracy: 0.6959\n",
      "Epoch 152/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.6960 - accuracy: 0.6939\n",
      "Epoch 153/500\n",
      "64/64 [==============================] - 63s 979ms/step - loss: 0.6933 - accuracy: 0.6925\n",
      "Epoch 154/500\n",
      "64/64 [==============================] - 57s 890ms/step - loss: 0.6824 - accuracy: 0.7116\n",
      "Epoch 155/500\n",
      "64/64 [==============================] - 59s 925ms/step - loss: 0.6862 - accuracy: 0.7023\n",
      "Epoch 156/500\n",
      "64/64 [==============================] - 60s 931ms/step - loss: 0.6895 - accuracy: 0.6969\n",
      "Epoch 157/500\n",
      "64/64 [==============================] - 62s 971ms/step - loss: 0.7034 - accuracy: 0.6949\n",
      "Epoch 158/500\n",
      "64/64 [==============================] - 57s 892ms/step - loss: 0.6983 - accuracy: 0.6920\n",
      "Epoch 159/500\n",
      "64/64 [==============================] - 62s 968ms/step - loss: 0.6906 - accuracy: 0.7096\n",
      "Epoch 160/500\n",
      "64/64 [==============================] - 57s 887ms/step - loss: 0.7040 - accuracy: 0.6783\n",
      "Epoch 161/500\n",
      "64/64 [==============================] - 63s 981ms/step - loss: 0.6855 - accuracy: 0.6871\n",
      "Epoch 162/500\n",
      "64/64 [==============================] - 59s 930ms/step - loss: 0.7014 - accuracy: 0.6915\n",
      "Epoch 163/500\n",
      "64/64 [==============================] - 64s 1s/step - loss: 0.6871 - accuracy: 0.6871\n",
      "Epoch 164/500\n",
      "64/64 [==============================] - 64s 1s/step - loss: 0.6849 - accuracy: 0.6964\n",
      "Epoch 165/500\n",
      "64/64 [==============================] - 61s 962ms/step - loss: 0.6983 - accuracy: 0.6832\n",
      "Epoch 166/500\n",
      "64/64 [==============================] - 59s 927ms/step - loss: 0.6836 - accuracy: 0.6934\n",
      "Epoch 167/500\n",
      "64/64 [==============================] - 62s 966ms/step - loss: 0.6825 - accuracy: 0.6890\n",
      "Epoch 168/500\n",
      "64/64 [==============================] - 57s 887ms/step - loss: 0.6727 - accuracy: 0.7067\n",
      "Epoch 169/500\n",
      "64/64 [==============================] - 62s 967ms/step - loss: 0.6796 - accuracy: 0.7027\n",
      "Epoch 170/500\n",
      "64/64 [==============================] - 59s 926ms/step - loss: 0.6684 - accuracy: 0.7150\n",
      "Epoch 171/500\n",
      "64/64 [==============================] - 59s 924ms/step - loss: 0.6914 - accuracy: 0.6983\n",
      "Epoch 172/500\n",
      "64/64 [==============================] - 60s 943ms/step - loss: 0.6927 - accuracy: 0.6900\n",
      "Epoch 173/500\n",
      "64/64 [==============================] - 62s 930ms/step - loss: 0.6994 - accuracy: 0.6871\n",
      "Epoch 174/500\n",
      "64/64 [==============================] - 59s 928ms/step - loss: 0.6908 - accuracy: 0.6969\n",
      "Epoch 175/500\n",
      "64/64 [==============================] - 63s 979ms/step - loss: 0.6935 - accuracy: 0.6890\n",
      "Epoch 176/500\n",
      "64/64 [==============================] - 72s 1s/step - loss: 0.6769 - accuracy: 0.6988\n",
      "Epoch 177/500\n",
      "64/64 [==============================] - 56s 871ms/step - loss: 0.6579 - accuracy: 0.7076\n",
      "Epoch 178/500\n",
      "64/64 [==============================] - 57s 895ms/step - loss: 0.6878 - accuracy: 0.6890\n",
      "Epoch 179/500\n",
      "64/64 [==============================] - 55s 867ms/step - loss: 0.6694 - accuracy: 0.7071\n",
      "Epoch 180/500\n",
      "64/64 [==============================] - 56s 874ms/step - loss: 0.6573 - accuracy: 0.7125\n",
      "Epoch 181/500\n",
      "64/64 [==============================] - 57s 894ms/step - loss: 0.6905 - accuracy: 0.7081\n",
      "Epoch 182/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.6858 - accuracy: 0.7116\n",
      "Epoch 183/500\n",
      "64/64 [==============================] - 59s 915ms/step - loss: 0.6743 - accuracy: 0.7037\n",
      "Epoch 184/500\n",
      "64/64 [==============================] - 57s 895ms/step - loss: 0.6834 - accuracy: 0.6954\n",
      "Epoch 185/500\n",
      "64/64 [==============================] - 58s 911ms/step - loss: 0.6640 - accuracy: 0.7238\n",
      "Epoch 186/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.6609 - accuracy: 0.7189\n",
      "Epoch 187/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.6740 - accuracy: 0.7047\n",
      "Epoch 188/500\n",
      "64/64 [==============================] - 57s 898ms/step - loss: 0.6743 - accuracy: 0.7013\n",
      "Epoch 189/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.6704 - accuracy: 0.6964\n",
      "Epoch 190/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.6831 - accuracy: 0.7042\n",
      "Epoch 191/500\n",
      "64/64 [==============================] - 58s 903ms/step - loss: 0.6553 - accuracy: 0.7057\n",
      "Epoch 192/500\n",
      "64/64 [==============================] - 58s 898ms/step - loss: 0.6547 - accuracy: 0.7194\n",
      "Epoch 193/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.6862 - accuracy: 0.6983\n",
      "Epoch 194/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.6700 - accuracy: 0.7052\n",
      "Epoch 195/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.6539 - accuracy: 0.7116\n",
      "Epoch 196/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.6547 - accuracy: 0.7165\n",
      "Epoch 197/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.6493 - accuracy: 0.7111\n",
      "Epoch 198/500\n",
      "64/64 [==============================] - 57s 898ms/step - loss: 0.6641 - accuracy: 0.7106\n",
      "Epoch 199/500\n",
      "64/64 [==============================] - 57s 897ms/step - loss: 0.6626 - accuracy: 0.7091\n",
      "Epoch 200/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.6422 - accuracy: 0.7302\n",
      "Epoch 201/500\n",
      "64/64 [==============================] - 59s 916ms/step - loss: 0.6566 - accuracy: 0.7111\n",
      "Epoch 202/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.6432 - accuracy: 0.7204\n",
      "Epoch 203/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.6570 - accuracy: 0.7194\n",
      "Epoch 204/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.6660 - accuracy: 0.7130\n",
      "Epoch 205/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.6432 - accuracy: 0.7282\n",
      "Epoch 206/500\n",
      "64/64 [==============================] - 58s 903ms/step - loss: 0.6584 - accuracy: 0.7199\n",
      "Epoch 207/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.6361 - accuracy: 0.7223\n",
      "Epoch 208/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.6478 - accuracy: 0.7184\n",
      "Epoch 209/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.6537 - accuracy: 0.7233\n",
      "Epoch 210/500\n",
      "64/64 [==============================] - 57s 896ms/step - loss: 0.6499 - accuracy: 0.7243\n",
      "Epoch 211/500\n",
      "64/64 [==============================] - 58s 903ms/step - loss: 0.6556 - accuracy: 0.7111\n",
      "Epoch 212/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 58s 904ms/step - loss: 0.6402 - accuracy: 0.7179\n",
      "Epoch 213/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.6613 - accuracy: 0.7120\n",
      "Epoch 214/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.6506 - accuracy: 0.7116\n",
      "Epoch 215/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.6530 - accuracy: 0.7253\n",
      "Epoch 216/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.6272 - accuracy: 0.7297\n",
      "Epoch 217/500\n",
      "64/64 [==============================] - 58s 899ms/step - loss: 0.6434 - accuracy: 0.7272\n",
      "Epoch 218/500\n",
      "64/64 [==============================] - 58s 911ms/step - loss: 0.6414 - accuracy: 0.7326\n",
      "Epoch 219/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.6459 - accuracy: 0.7228\n",
      "Epoch 220/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.6380 - accuracy: 0.7243\n",
      "Epoch 221/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.6706 - accuracy: 0.7101\n",
      "Epoch 222/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.6417 - accuracy: 0.7184\n",
      "Epoch 223/500\n",
      "64/64 [==============================] - 58s 898ms/step - loss: 0.6628 - accuracy: 0.6993\n",
      "Epoch 224/500\n",
      "64/64 [==============================] - 58s 899ms/step - loss: 0.6335 - accuracy: 0.7287\n",
      "Epoch 225/500\n",
      "64/64 [==============================] - 58s 899ms/step - loss: 0.6480 - accuracy: 0.7228\n",
      "Epoch 226/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.6646 - accuracy: 0.7116\n",
      "Epoch 227/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.6445 - accuracy: 0.7277\n",
      "Epoch 228/500\n",
      "64/64 [==============================] - 58s 901ms/step - loss: 0.6408 - accuracy: 0.7233\n",
      "Epoch 229/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.6451 - accuracy: 0.7184\n",
      "Epoch 230/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.6418 - accuracy: 0.7150\n",
      "Epoch 231/500\n",
      "64/64 [==============================] - 58s 901ms/step - loss: 0.6261 - accuracy: 0.7341\n",
      "Epoch 232/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.6514 - accuracy: 0.7155\n",
      "Epoch 233/500\n",
      "64/64 [==============================] - 59s 919ms/step - loss: 0.6317 - accuracy: 0.7155\n",
      "Epoch 234/500\n",
      "64/64 [==============================] - 57s 898ms/step - loss: 0.6249 - accuracy: 0.7302\n",
      "Epoch 235/500\n",
      "64/64 [==============================] - 57s 898ms/step - loss: 0.6451 - accuracy: 0.7204\n",
      "Epoch 236/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.6302 - accuracy: 0.7253\n",
      "Epoch 237/500\n",
      "64/64 [==============================] - 58s 912ms/step - loss: 0.6380 - accuracy: 0.7155\n",
      "Epoch 238/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.6165 - accuracy: 0.7277\n",
      "Epoch 239/500\n",
      "64/64 [==============================] - 58s 898ms/step - loss: 0.6654 - accuracy: 0.7106\n",
      "Epoch 240/500\n",
      "64/64 [==============================] - 58s 912ms/step - loss: 0.6120 - accuracy: 0.7262\n",
      "Epoch 241/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.6259 - accuracy: 0.7356\n",
      "Epoch 242/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.6265 - accuracy: 0.7365\n",
      "Epoch 243/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.6393 - accuracy: 0.7223\n",
      "Epoch 244/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.6073 - accuracy: 0.7385\n",
      "Epoch 245/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.6512 - accuracy: 0.7189\n",
      "Epoch 246/500\n",
      "64/64 [==============================] - 58s 899ms/step - loss: 0.6368 - accuracy: 0.7155\n",
      "Epoch 247/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.6163 - accuracy: 0.7316\n",
      "Epoch 248/500\n",
      "64/64 [==============================] - 58s 913ms/step - loss: 0.6271 - accuracy: 0.7321\n",
      "Epoch 249/500\n",
      "64/64 [==============================] - 58s 901ms/step - loss: 0.6288 - accuracy: 0.7179\n",
      "Epoch 250/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.6123 - accuracy: 0.7429\n",
      "Epoch 251/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.6280 - accuracy: 0.7336\n",
      "Epoch 252/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.6154 - accuracy: 0.7424\n",
      "Epoch 253/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.6385 - accuracy: 0.7184\n",
      "Epoch 254/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.6139 - accuracy: 0.7311\n",
      "Epoch 255/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.6400 - accuracy: 0.7184\n",
      "Epoch 256/500\n",
      "64/64 [==============================] - 58s 899ms/step - loss: 0.6156 - accuracy: 0.7409\n",
      "Epoch 257/500\n",
      "64/64 [==============================] - 59s 920ms/step - loss: 0.6192 - accuracy: 0.7424\n",
      "Epoch 258/500\n",
      "64/64 [==============================] - 76s 1s/step - loss: 0.6339 - accuracy: 0.7262\n",
      "Epoch 259/500\n",
      "64/64 [==============================] - 59s 917ms/step - loss: 0.6243 - accuracy: 0.7238\n",
      "Epoch 260/500\n",
      "64/64 [==============================] - 56s 873ms/step - loss: 0.6294 - accuracy: 0.7302\n",
      "Epoch 261/500\n",
      "64/64 [==============================] - 57s 887ms/step - loss: 0.6232 - accuracy: 0.7400\n",
      "Epoch 262/500\n",
      "64/64 [==============================] - 59s 917ms/step - loss: 0.6313 - accuracy: 0.7238\n",
      "Epoch 263/500\n",
      "64/64 [==============================] - 56s 879ms/step - loss: 0.6343 - accuracy: 0.7302\n",
      "Epoch 264/500\n",
      "64/64 [==============================] - 64s 1s/step - loss: 0.6023 - accuracy: 0.7493\n",
      "Epoch 265/500\n",
      "64/64 [==============================] - 61s 951ms/step - loss: 0.5924 - accuracy: 0.7444\n",
      "Epoch 266/500\n",
      "64/64 [==============================] - 54s 841ms/step - loss: 0.6307 - accuracy: 0.7307\n",
      "Epoch 267/500\n",
      "64/64 [==============================] - 58s 911ms/step - loss: 0.6319 - accuracy: 0.7267\n",
      "Epoch 268/500\n",
      "64/64 [==============================] - 58s 913ms/step - loss: 0.6223 - accuracy: 0.7267\n",
      "Epoch 269/500\n",
      "64/64 [==============================] - 58s 914ms/step - loss: 0.6302 - accuracy: 0.7184\n",
      "Epoch 270/500\n",
      "64/64 [==============================] - 56s 879ms/step - loss: 0.6172 - accuracy: 0.7311\n",
      "Epoch 271/500\n",
      "64/64 [==============================] - 59s 922ms/step - loss: 0.6154 - accuracy: 0.7360\n",
      "Epoch 272/500\n",
      "64/64 [==============================] - 67s 1s/step - loss: 0.6016 - accuracy: 0.7346\n",
      "Epoch 273/500\n",
      "64/64 [==============================] - 56s 879ms/step - loss: 0.6247 - accuracy: 0.7356\n",
      "Epoch 274/500\n",
      "64/64 [==============================] - 61s 950ms/step - loss: 0.6060 - accuracy: 0.7326\n",
      "Epoch 275/500\n",
      "64/64 [==============================] - 59s 919ms/step - loss: 0.6373 - accuracy: 0.7204\n",
      "Epoch 276/500\n",
      "64/64 [==============================] - 54s 841ms/step - loss: 0.6057 - accuracy: 0.7434\n",
      "Epoch 277/500\n",
      "64/64 [==============================] - 56s 883ms/step - loss: 0.6253 - accuracy: 0.7351\n",
      "Epoch 278/500\n",
      "64/64 [==============================] - 63s 947ms/step - loss: 0.6032 - accuracy: 0.7360\n",
      "Epoch 279/500\n",
      "64/64 [==============================] - 56s 879ms/step - loss: 0.6150 - accuracy: 0.7321\n",
      "Epoch 280/500\n",
      "64/64 [==============================] - 61s 951ms/step - loss: 0.6084 - accuracy: 0.7419\n",
      "Epoch 281/500\n",
      "64/64 [==============================] - 58s 913ms/step - loss: 0.6199 - accuracy: 0.7282\n",
      "Epoch 282/500\n",
      "64/64 [==============================] - 56s 877ms/step - loss: 0.6196 - accuracy: 0.7336\n",
      "Epoch 283/500\n",
      "64/64 [==============================] - 61s 928ms/step - loss: 0.6308 - accuracy: 0.7292\n",
      "Epoch 284/500\n",
      "64/64 [==============================] - 56s 873ms/step - loss: 0.6151 - accuracy: 0.7429\n",
      "Epoch 285/500\n",
      "64/64 [==============================] - 56s 873ms/step - loss: 0.6170 - accuracy: 0.7434\n",
      "Epoch 286/500\n",
      "64/64 [==============================] - 62s 964ms/step - loss: 0.5970 - accuracy: 0.7449\n",
      "Epoch 287/500\n",
      "64/64 [==============================] - 56s 882ms/step - loss: 0.6199 - accuracy: 0.7326\n",
      "Epoch 288/500\n",
      "64/64 [==============================] - 56s 878ms/step - loss: 0.6155 - accuracy: 0.7517\n",
      "Epoch 289/500\n",
      "64/64 [==============================] - 57s 889ms/step - loss: 0.6354 - accuracy: 0.7214\n",
      "Epoch 290/500\n",
      "64/64 [==============================] - 59s 928ms/step - loss: 0.5898 - accuracy: 0.7360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "64/64 [==============================] - 61s 949ms/step - loss: 0.5980 - accuracy: 0.7507\n",
      "Epoch 292/500\n",
      "64/64 [==============================] - 56s 878ms/step - loss: 0.5924 - accuracy: 0.7532\n",
      "Epoch 293/500\n",
      "64/64 [==============================] - 56s 875ms/step - loss: 0.6122 - accuracy: 0.7346\n",
      "Epoch 294/500\n",
      "64/64 [==============================] - 59s 923ms/step - loss: 0.5874 - accuracy: 0.7439\n",
      "Epoch 295/500\n",
      "64/64 [==============================] - 62s 968ms/step - loss: 0.6025 - accuracy: 0.7424\n",
      "Epoch 296/500\n",
      "64/64 [==============================] - 68s 1s/step - loss: 0.6113 - accuracy: 0.7449\n",
      "Epoch 297/500\n",
      "64/64 [==============================] - 55s 865ms/step - loss: 0.6214 - accuracy: 0.7365\n",
      "Epoch 298/500\n",
      "64/64 [==============================] - 57s 888ms/step - loss: 0.5969 - accuracy: 0.7449\n",
      "Epoch 299/500\n",
      "64/64 [==============================] - 56s 868ms/step - loss: 0.5965 - accuracy: 0.7473\n",
      "Epoch 300/500\n",
      "64/64 [==============================] - 56s 874ms/step - loss: 0.6052 - accuracy: 0.7400\n",
      "Epoch 301/500\n",
      "64/64 [==============================] - 57s 899ms/step - loss: 0.6013 - accuracy: 0.7385\n",
      "Epoch 302/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.5984 - accuracy: 0.7483\n",
      "Epoch 303/500\n",
      "64/64 [==============================] - 57s 897ms/step - loss: 0.6182 - accuracy: 0.7346\n",
      "Epoch 304/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.6327 - accuracy: 0.7262\n",
      "Epoch 305/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.6157 - accuracy: 0.7341\n",
      "Epoch 306/500\n",
      "64/64 [==============================] - 58s 901ms/step - loss: 0.6096 - accuracy: 0.7458\n",
      "Epoch 307/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.5895 - accuracy: 0.7478\n",
      "Epoch 308/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.6007 - accuracy: 0.7429\n",
      "Epoch 309/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.6016 - accuracy: 0.7434\n",
      "Epoch 310/500\n",
      "64/64 [==============================] - 58s 911ms/step - loss: 0.6092 - accuracy: 0.7311\n",
      "Epoch 311/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.5965 - accuracy: 0.7365\n",
      "Epoch 312/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.5952 - accuracy: 0.7478\n",
      "Epoch 313/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.6105 - accuracy: 0.7429\n",
      "Epoch 314/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.5873 - accuracy: 0.7571\n",
      "Epoch 315/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5813 - accuracy: 0.7532\n",
      "Epoch 316/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.6035 - accuracy: 0.7463\n",
      "Epoch 317/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.6085 - accuracy: 0.7321\n",
      "Epoch 318/500\n",
      "64/64 [==============================] - 58s 898ms/step - loss: 0.5920 - accuracy: 0.7458\n",
      "Epoch 319/500\n",
      "64/64 [==============================] - 58s 912ms/step - loss: 0.5811 - accuracy: 0.7532\n",
      "Epoch 320/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.5834 - accuracy: 0.7581\n",
      "Epoch 321/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.5828 - accuracy: 0.7581\n",
      "Epoch 322/500\n",
      "64/64 [==============================] - 57s 898ms/step - loss: 0.5867 - accuracy: 0.7453\n",
      "Epoch 323/500\n",
      "64/64 [==============================] - 58s 901ms/step - loss: 0.5988 - accuracy: 0.7453\n",
      "Epoch 324/500\n",
      "64/64 [==============================] - 57s 896ms/step - loss: 0.5862 - accuracy: 0.7478\n",
      "Epoch 325/500\n",
      "64/64 [==============================] - 57s 897ms/step - loss: 0.5781 - accuracy: 0.7556\n",
      "Epoch 326/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.5783 - accuracy: 0.7586\n",
      "Epoch 327/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.5884 - accuracy: 0.7507\n",
      "Epoch 328/500\n",
      "64/64 [==============================] - 58s 912ms/step - loss: 0.5838 - accuracy: 0.7551\n",
      "Epoch 329/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.5949 - accuracy: 0.7434\n",
      "Epoch 330/500\n",
      "64/64 [==============================] - 58s 903ms/step - loss: 0.5742 - accuracy: 0.7649\n",
      "Epoch 331/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.5844 - accuracy: 0.7522\n",
      "Epoch 332/500\n",
      "64/64 [==============================] - 58s 911ms/step - loss: 0.6054 - accuracy: 0.7375\n",
      "Epoch 333/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5696 - accuracy: 0.7581\n",
      "Epoch 334/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5911 - accuracy: 0.7429\n",
      "Epoch 335/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.5808 - accuracy: 0.7586\n",
      "Epoch 336/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.6137 - accuracy: 0.7400\n",
      "Epoch 337/500\n",
      "64/64 [==============================] - 58s 903ms/step - loss: 0.6156 - accuracy: 0.7370\n",
      "Epoch 338/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.5866 - accuracy: 0.7449\n",
      "Epoch 339/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.5905 - accuracy: 0.7483\n",
      "Epoch 340/500\n",
      "64/64 [==============================] - 59s 916ms/step - loss: 0.5962 - accuracy: 0.7522\n",
      "Epoch 341/500\n",
      "64/64 [==============================] - 58s 903ms/step - loss: 0.5735 - accuracy: 0.7488\n",
      "Epoch 342/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.5908 - accuracy: 0.7551\n",
      "Epoch 343/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5664 - accuracy: 0.7591\n",
      "Epoch 344/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.5773 - accuracy: 0.7449\n",
      "Epoch 345/500\n",
      "64/64 [==============================] - 59s 915ms/step - loss: 0.5875 - accuracy: 0.7365\n",
      "Epoch 346/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5876 - accuracy: 0.7527\n",
      "Epoch 347/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.5684 - accuracy: 0.7561\n",
      "Epoch 348/500\n",
      "64/64 [==============================] - 57s 894ms/step - loss: 0.5632 - accuracy: 0.7649\n",
      "Epoch 349/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.5997 - accuracy: 0.7532\n",
      "Epoch 350/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.5815 - accuracy: 0.7512\n",
      "Epoch 351/500\n",
      "64/64 [==============================] - 58s 912ms/step - loss: 0.5989 - accuracy: 0.7405\n",
      "Epoch 352/500\n",
      "64/64 [==============================] - 58s 901ms/step - loss: 0.5930 - accuracy: 0.7380\n",
      "Epoch 353/500\n",
      "64/64 [==============================] - 57s 898ms/step - loss: 0.5826 - accuracy: 0.7409\n",
      "Epoch 354/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.5791 - accuracy: 0.7502\n",
      "Epoch 355/500\n",
      "64/64 [==============================] - 57s 899ms/step - loss: 0.5704 - accuracy: 0.7586\n",
      "Epoch 356/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.5983 - accuracy: 0.7532\n",
      "Epoch 357/500\n",
      "64/64 [==============================] - 57s 896ms/step - loss: 0.5855 - accuracy: 0.7478\n",
      "Epoch 358/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.5810 - accuracy: 0.7493\n",
      "Epoch 359/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.5815 - accuracy: 0.7453\n",
      "Epoch 360/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.5614 - accuracy: 0.7615\n",
      "Epoch 361/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.5914 - accuracy: 0.7483\n",
      "Epoch 362/500\n",
      "64/64 [==============================] - 57s 896ms/step - loss: 0.5882 - accuracy: 0.7434\n",
      "Epoch 363/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.6135 - accuracy: 0.7346\n",
      "Epoch 364/500\n",
      "64/64 [==============================] - 58s 903ms/step - loss: 0.5801 - accuracy: 0.7581\n",
      "Epoch 365/500\n",
      "64/64 [==============================] - 58s 903ms/step - loss: 0.5689 - accuracy: 0.7556\n",
      "Epoch 366/500\n",
      "64/64 [==============================] - 57s 898ms/step - loss: 0.5805 - accuracy: 0.7512\n",
      "Epoch 367/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.5889 - accuracy: 0.7512\n",
      "Epoch 368/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.5676 - accuracy: 0.7512\n",
      "Epoch 369/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 58s 908ms/step - loss: 0.5778 - accuracy: 0.7493\n",
      "Epoch 370/500\n",
      "64/64 [==============================] - 58s 898ms/step - loss: 0.5752 - accuracy: 0.7581\n",
      "Epoch 371/500\n",
      "64/64 [==============================] - 58s 903ms/step - loss: 0.5823 - accuracy: 0.7625\n",
      "Epoch 372/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5649 - accuracy: 0.7517\n",
      "Epoch 373/500\n",
      "64/64 [==============================] - 57s 898ms/step - loss: 0.5701 - accuracy: 0.7679\n",
      "Epoch 374/500\n",
      "64/64 [==============================] - 63s 981ms/step - loss: 0.5962 - accuracy: 0.7493\n",
      "Epoch 375/500\n",
      "64/64 [==============================] - 64s 1s/step - loss: 0.5714 - accuracy: 0.7625\n",
      "Epoch 376/500\n",
      "64/64 [==============================] - 69s 1s/step - loss: 0.5852 - accuracy: 0.7380\n",
      "Epoch 377/500\n",
      "64/64 [==============================] - 60s 934ms/step - loss: 0.5864 - accuracy: 0.7571\n",
      "Epoch 378/500\n",
      "64/64 [==============================] - 64s 1000ms/step - loss: 0.5672 - accuracy: 0.7610\n",
      "Epoch 379/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.5628 - accuracy: 0.7679\n",
      "Epoch 380/500\n",
      "64/64 [==============================] - 64s 999ms/step - loss: 0.5908 - accuracy: 0.7527\n",
      "Epoch 381/500\n",
      "64/64 [==============================] - 64s 1000ms/step - loss: 0.5864 - accuracy: 0.7439\n",
      "Epoch 382/500\n",
      "64/64 [==============================] - 72s 1s/step - loss: 0.5828 - accuracy: 0.7547\n",
      "Epoch 383/500\n",
      "64/64 [==============================] - 61s 952ms/step - loss: 0.5671 - accuracy: 0.7610\n",
      "Epoch 384/500\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.5480 - accuracy: 0.7640\n",
      "Epoch 385/500\n",
      "64/64 [==============================] - 67s 1s/step - loss: 0.5649 - accuracy: 0.7620\n",
      "Epoch 386/500\n",
      "64/64 [==============================] - 67s 1s/step - loss: 0.5625 - accuracy: 0.7532\n",
      "Epoch 387/500\n",
      "64/64 [==============================] - 62s 966ms/step - loss: 0.5816 - accuracy: 0.7537\n",
      "Epoch 388/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.5681 - accuracy: 0.7556\n",
      "Epoch 389/500\n",
      "64/64 [==============================] - 68s 1s/step - loss: 0.5618 - accuracy: 0.7610\n",
      "Epoch 390/500\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.5870 - accuracy: 0.7414\n",
      "Epoch 391/500\n",
      "64/64 [==============================] - 71s 1s/step - loss: 0.5844 - accuracy: 0.7556\n",
      "Epoch 392/500\n",
      "64/64 [==============================] - 67s 1s/step - loss: 0.5645 - accuracy: 0.7522\n",
      "Epoch 393/500\n",
      "64/64 [==============================] - 64s 995ms/step - loss: 0.5872 - accuracy: 0.7532\n",
      "Epoch 394/500\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.5703 - accuracy: 0.7595\n",
      "Epoch 395/500\n",
      "64/64 [==============================] - 63s 985ms/step - loss: 0.5800 - accuracy: 0.7502\n",
      "Epoch 396/500\n",
      "64/64 [==============================] - 70s 1s/step - loss: 0.5759 - accuracy: 0.7571\n",
      "Epoch 397/500\n",
      "64/64 [==============================] - 70s 1s/step - loss: 0.5754 - accuracy: 0.7576\n",
      "Epoch 398/500\n",
      "64/64 [==============================] - 68s 1s/step - loss: 0.5676 - accuracy: 0.7478\n",
      "Epoch 399/500\n",
      "64/64 [==============================] - 67s 1s/step - loss: 0.5892 - accuracy: 0.7512\n",
      "Epoch 400/500\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.5750 - accuracy: 0.7586\n",
      "Epoch 401/500\n",
      "64/64 [==============================] - 61s 961ms/step - loss: 0.5588 - accuracy: 0.7664\n",
      "Epoch 402/500\n",
      "64/64 [==============================] - 67s 1s/step - loss: 0.5482 - accuracy: 0.7698\n",
      "Epoch 403/500\n",
      "64/64 [==============================] - 69s 1s/step - loss: 0.5750 - accuracy: 0.7615\n",
      "Epoch 404/500\n",
      "64/64 [==============================] - 63s 979ms/step - loss: 0.5658 - accuracy: 0.7620\n",
      "Epoch 405/500\n",
      "64/64 [==============================] - 69s 1s/step - loss: 0.5599 - accuracy: 0.7669\n",
      "Epoch 406/500\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.5489 - accuracy: 0.7713\n",
      "Epoch 407/500\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.5716 - accuracy: 0.7610\n",
      "Epoch 408/500\n",
      "64/64 [==============================] - 67s 1s/step - loss: 0.5598 - accuracy: 0.7595\n",
      "Epoch 409/500\n",
      "64/64 [==============================] - 63s 979ms/step - loss: 0.5807 - accuracy: 0.7615\n",
      "Epoch 410/500\n",
      "64/64 [==============================] - 64s 1s/step - loss: 0.5565 - accuracy: 0.7674\n",
      "Epoch 411/500\n",
      "64/64 [==============================] - 67s 1s/step - loss: 0.5581 - accuracy: 0.7561\n",
      "Epoch 412/500\n",
      "64/64 [==============================] - 67s 1s/step - loss: 0.5775 - accuracy: 0.7620\n",
      "Epoch 413/500\n",
      "64/64 [==============================] - 69s 1s/step - loss: 0.5682 - accuracy: 0.7600\n",
      "Epoch 414/500\n",
      "64/64 [==============================] - 64s 990ms/step - loss: 0.5524 - accuracy: 0.7659\n",
      "Epoch 415/500\n",
      "64/64 [==============================] - 63s 984ms/step - loss: 0.5855 - accuracy: 0.7512\n",
      "Epoch 416/500\n",
      "64/64 [==============================] - 63s 971ms/step - loss: 0.5743 - accuracy: 0.7517\n",
      "Epoch 417/500\n",
      "64/64 [==============================] - 82s 1s/step - loss: 0.5792 - accuracy: 0.7507\n",
      "Epoch 418/500\n",
      "64/64 [==============================] - 56s 877ms/step - loss: 0.5588 - accuracy: 0.7708\n",
      "Epoch 419/500\n",
      "64/64 [==============================] - 57s 884ms/step - loss: 0.5722 - accuracy: 0.7507\n",
      "Epoch 420/500\n",
      "64/64 [==============================] - 57s 887ms/step - loss: 0.5673 - accuracy: 0.7640\n",
      "Epoch 421/500\n",
      "64/64 [==============================] - 56s 877ms/step - loss: 0.5341 - accuracy: 0.7703\n",
      "Epoch 422/500\n",
      "64/64 [==============================] - 57s 898ms/step - loss: 0.5506 - accuracy: 0.7708\n",
      "Epoch 423/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.5777 - accuracy: 0.7483\n",
      "Epoch 424/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.5408 - accuracy: 0.7703\n",
      "Epoch 425/500\n",
      "64/64 [==============================] - 58s 903ms/step - loss: 0.5882 - accuracy: 0.7439\n",
      "Epoch 426/500\n",
      "64/64 [==============================] - 59s 917ms/step - loss: 0.5592 - accuracy: 0.7556\n",
      "Epoch 427/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.5613 - accuracy: 0.7640\n",
      "Epoch 428/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5564 - accuracy: 0.7620\n",
      "Epoch 429/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.5407 - accuracy: 0.7742\n",
      "Epoch 430/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.5504 - accuracy: 0.7625\n",
      "Epoch 431/500\n",
      "64/64 [==============================] - 58s 914ms/step - loss: 0.5655 - accuracy: 0.7586\n",
      "Epoch 432/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5553 - accuracy: 0.7708\n",
      "Epoch 433/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.5759 - accuracy: 0.7444\n",
      "Epoch 434/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.5514 - accuracy: 0.7537\n",
      "Epoch 435/500\n",
      "64/64 [==============================] - 57s 898ms/step - loss: 0.5753 - accuracy: 0.7547\n",
      "Epoch 436/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.5418 - accuracy: 0.7649\n",
      "Epoch 437/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.5480 - accuracy: 0.7762\n",
      "Epoch 438/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.5656 - accuracy: 0.7547\n",
      "Epoch 439/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5643 - accuracy: 0.7723\n",
      "Epoch 440/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.5511 - accuracy: 0.7630\n",
      "Epoch 441/500\n",
      "64/64 [==============================] - 59s 919ms/step - loss: 0.5572 - accuracy: 0.7640\n",
      "Epoch 442/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.5475 - accuracy: 0.7698\n",
      "Epoch 443/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5628 - accuracy: 0.7605\n",
      "Epoch 444/500\n",
      "64/64 [==============================] - 58s 911ms/step - loss: 0.5665 - accuracy: 0.7576\n",
      "Epoch 445/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.5675 - accuracy: 0.7625\n",
      "Epoch 446/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.5522 - accuracy: 0.7640\n",
      "Epoch 447/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.5326 - accuracy: 0.7767\n",
      "Epoch 448/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 58s 901ms/step - loss: 0.5530 - accuracy: 0.7669\n",
      "Epoch 449/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.5492 - accuracy: 0.7674\n",
      "Epoch 450/500\n",
      "64/64 [==============================] - 58s 901ms/step - loss: 0.5602 - accuracy: 0.7635\n",
      "Epoch 451/500\n",
      "64/64 [==============================] - 57s 894ms/step - loss: 0.5625 - accuracy: 0.7674\n",
      "Epoch 452/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.5560 - accuracy: 0.7600\n",
      "Epoch 453/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5558 - accuracy: 0.7752\n",
      "Epoch 454/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.5581 - accuracy: 0.7561\n",
      "Epoch 455/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.5625 - accuracy: 0.7591\n",
      "Epoch 456/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.5598 - accuracy: 0.7649\n",
      "Epoch 457/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.5418 - accuracy: 0.7689\n",
      "Epoch 458/500\n",
      "64/64 [==============================] - 57s 898ms/step - loss: 0.5357 - accuracy: 0.7757\n",
      "Epoch 459/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.5580 - accuracy: 0.7684\n",
      "Epoch 460/500\n",
      "64/64 [==============================] - 57s 895ms/step - loss: 0.5484 - accuracy: 0.7718\n",
      "Epoch 461/500\n",
      "64/64 [==============================] - 58s 901ms/step - loss: 0.5496 - accuracy: 0.7649\n",
      "Epoch 462/500\n",
      "64/64 [==============================] - 58s 899ms/step - loss: 0.5555 - accuracy: 0.7659\n",
      "Epoch 463/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5595 - accuracy: 0.7674\n",
      "Epoch 464/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.5354 - accuracy: 0.7649\n",
      "Epoch 465/500\n",
      "64/64 [==============================] - 57s 897ms/step - loss: 0.5403 - accuracy: 0.7811\n",
      "Epoch 466/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.5584 - accuracy: 0.7659\n",
      "Epoch 467/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.5300 - accuracy: 0.7747\n",
      "Epoch 468/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.5418 - accuracy: 0.7664\n",
      "Epoch 469/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5547 - accuracy: 0.7698\n",
      "Epoch 470/500\n",
      "64/64 [==============================] - 58s 898ms/step - loss: 0.5527 - accuracy: 0.7718\n",
      "Epoch 471/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5470 - accuracy: 0.7610\n",
      "Epoch 472/500\n",
      "64/64 [==============================] - 57s 896ms/step - loss: 0.5488 - accuracy: 0.7708\n",
      "Epoch 473/500\n",
      "64/64 [==============================] - 59s 916ms/step - loss: 0.5489 - accuracy: 0.7782\n",
      "Epoch 474/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.5585 - accuracy: 0.7649\n",
      "Epoch 475/500\n",
      "64/64 [==============================] - 58s 901ms/step - loss: 0.5298 - accuracy: 0.7733\n",
      "Epoch 476/500\n",
      "64/64 [==============================] - 59s 918ms/step - loss: 0.5529 - accuracy: 0.7654\n",
      "Epoch 477/500\n",
      "64/64 [==============================] - 59s 918ms/step - loss: 0.5276 - accuracy: 0.7835\n",
      "Epoch 478/500\n",
      "64/64 [==============================] - 59s 916ms/step - loss: 0.5495 - accuracy: 0.7571\n",
      "Epoch 479/500\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.5567 - accuracy: 0.7610\n",
      "Epoch 480/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.5250 - accuracy: 0.7796\n",
      "Epoch 481/500\n",
      "64/64 [==============================] - 58s 904ms/step - loss: 0.5540 - accuracy: 0.7703\n",
      "Epoch 482/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.5452 - accuracy: 0.7733\n",
      "Epoch 483/500\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.5645 - accuracy: 0.7581\n",
      "Epoch 484/500\n",
      "64/64 [==============================] - 58s 899ms/step - loss: 0.5466 - accuracy: 0.7689\n",
      "Epoch 485/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.5410 - accuracy: 0.7689\n",
      "Epoch 486/500\n",
      "64/64 [==============================] - 58s 913ms/step - loss: 0.5534 - accuracy: 0.7571\n",
      "Epoch 487/500\n",
      "64/64 [==============================] - 58s 909ms/step - loss: 0.5710 - accuracy: 0.7561\n",
      "Epoch 488/500\n",
      "64/64 [==============================] - 58s 911ms/step - loss: 0.5497 - accuracy: 0.7625\n",
      "Epoch 489/500\n",
      "64/64 [==============================] - 58s 910ms/step - loss: 0.5415 - accuracy: 0.7635\n",
      "Epoch 490/500\n",
      "64/64 [==============================] - 58s 905ms/step - loss: 0.5448 - accuracy: 0.7693\n",
      "Epoch 491/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.5497 - accuracy: 0.7679\n",
      "Epoch 492/500\n",
      "64/64 [==============================] - 58s 901ms/step - loss: 0.5245 - accuracy: 0.7796\n",
      "Epoch 493/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.5175 - accuracy: 0.7806\n",
      "Epoch 494/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.5451 - accuracy: 0.7762\n",
      "Epoch 495/500\n",
      "64/64 [==============================] - 58s 902ms/step - loss: 0.5389 - accuracy: 0.7786\n",
      "Epoch 496/500\n",
      "64/64 [==============================] - 58s 906ms/step - loss: 0.5400 - accuracy: 0.7728\n",
      "Epoch 497/500\n",
      "64/64 [==============================] - 58s 908ms/step - loss: 0.5373 - accuracy: 0.7801\n",
      "Epoch 498/500\n",
      "64/64 [==============================] - 58s 911ms/step - loss: 0.5430 - accuracy: 0.7718\n",
      "Epoch 499/500\n",
      "64/64 [==============================] - 58s 899ms/step - loss: 0.5526 - accuracy: 0.7659\n",
      "Epoch 500/500\n",
      "64/64 [==============================] - 59s 915ms/step - loss: 0.5366 - accuracy: 0.7713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dceb8a2410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4808f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 9s 224ms/step - loss: 0.4553 - accuracy: 0.8219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.455317884683609, 0.8219178318977356]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "966f20ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4411850c-4aee-40c3-901a-bbfafbd0209c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4411850c-4aee-40c3-901a-bbfafbd0209c/assets\n"
     ]
    }
   ],
   "source": [
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "665934cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf2c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
